{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a50611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_catalyst_design.discrete_space_diffusion import AbsorbingStateNoiser, CosineScheduler, LinearScheduler, ExponentialScheduler\n",
    "from gen_catalyst_design.discrete_space_diffusion.Dataset import get_dataloaders_from_atoms_list\n",
    "from ase.io import read\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from ase.io import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0095cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_absorbing_state = True\n",
    "mask_classes = True\n",
    "element_pool = [\"Au\",\"Cu\",\"Pd\",\"Rh\",\"Ni\",\"Ga\"]\n",
    "if use_absorbing_state:\n",
    "    element_pool = [\"(X)\"] + element_pool\n",
    "\n",
    "atoms_list = read(\"dataset.traj\", index=\":\")\n",
    "if mask_classes:\n",
    "    for atoms in atoms_list:\n",
    "        atoms.info[\"class\"] = 0\n",
    "\n",
    "train_loader, val_loader = get_dataloaders_from_atoms_list(\n",
    "    atoms_list=atoms_list,\n",
    "    element_pool=element_pool,\n",
    "    batch_size=10,\n",
    "    do_initial_shuffling=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b65887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'abc.GraphBatch'>\n",
      "torch.Size([21, 3])\n",
      "torch.Size([21, 3])\n",
      "torch.Size([21, 3])\n",
      "torch.Size([21, 3])\n",
      "torch.Size([21, 3])\n",
      "torch.Size([21, 3])\n",
      "torch.Size([21, 3])\n",
      "torch.Size([21, 3])\n",
      "torch.Size([21, 3])\n",
      "torch.Size([21, 3])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(type(batch))\n",
    "    graphs = batch.to_data_list()\n",
    "    atoms_list = [graph.to_atoms(element_pool) for graph in graphs]\n",
    "    write(filename=\"batched.traj\", images=atoms_list)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20617062",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineScheduler(beta_max=1.0, beta_min=1e-3)\n",
    "noiser = AbsorbingStateNoiser(element_pool=element_pool)\n",
    "noiser.pre_compute_accum_q_matrices(scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(p, q):\n",
    "    mask_indices = q > 0.0\n",
    "    #print(mask_indices)\n",
    "    #print(mask_indices.shape)\n",
    "    #print(p[mask_indices])\n",
    "    #print(p[mask_indices]*torch.log(q[mask_indices]))\n",
    "    return -(p[mask_indices]*torch.log(q[mask_indices])).sum()\n",
    "\n",
    "def get_denoise_probs(\n",
    "        denoise_logits,\n",
    "        x_t,\n",
    "        batch,\n",
    "        time,\n",
    "        scheduler\n",
    "    ):\n",
    "    denoise_probs = F.softmax(denoise_logits, dim=-1)\n",
    "    x0s = [F.one_hot(torch.tensor(i), num_classes=len(element_pool))*torch.ones(size=(len(x_t), 1)) for i in range(len(element_pool))]\n",
    "    #print(x0s[0])\n",
    "    q_revs_tot = torch.stack([noiser.get_reverse_transition_probabilities(\n",
    "        x0_batch=x0*1.0,\n",
    "        x_t_batch=x_t*1.0, \n",
    "        time_batch=time[batch.batch], \n",
    "        scheduler=scheduler\n",
    "    ) for x0 in x0s\n",
    "    ])\n",
    "    #print(q_revs_tot[1])\n",
    "    #result_prob = 0.0\n",
    "    #for q_rev in q_revs_tot:\n",
    "    #    result_prob+= denoise_probs*q_rev\n",
    "    #print()\n",
    "    #print(q_revs_tot[0])\n",
    "    #print(torch.argwhere(q_revs_tot[0] > 0.0))\n",
    "    #print(q_revs_tot[3])\n",
    "    #result_probs = torch.zeros_like(x_t)\n",
    "    #_, categories = result_probs.shape\n",
    "    #for category in categories:\n",
    "    #    for q_rev in q_revs_tot:\n",
    "    #        q_rev*denoise_probs\n",
    "    #print(torch.argwhere(q_revs_tot > 0.0))\n",
    "    \n",
    "    #print(q_revs_tot[2])\n",
    "    #print(denoise_probs[None, :, :])\n",
    "    summed_probs = (denoise_probs[None, :, :] * q_revs_tot).sum(dim=0)\n",
    "    #print(summed_probs)\n",
    "    #norm_const = summed_probs.sum(dim=1, keepdim=True)\n",
    "    #reg_indices = (norm_const > 0.0).reshape(shape=(len(summed_probs),))\n",
    "    #normalized_probs = summed_probs[reg_indices]/norm_const[reg_indices]\n",
    "    \n",
    "    return summed_probs/summed_probs.sum(dim=1, keepdim=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0934eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "for batch in train_loader:\n",
    "    loss = 0.0\n",
    "    time = scheduler.sample_time(n_samples=batch.batch_size, t_span=(800,scheduler.t_final))\n",
    "    x_t = noiser.noise_x0_xt(x0_batch=batch.x*1.0, time_batch=time[batch.batch])\n",
    "    q_revs_loss = noiser.get_reverse_transition_probabilities(\n",
    "        x0_batch=batch.x*1.0,\n",
    "        x_t_batch=x_t*1.0, \n",
    "        time_batch=time[batch.batch], \n",
    "        scheduler=scheduler\n",
    "    )\n",
    "    print(x_t[0])\n",
    "    denoise_logits = torch.rand_like(x_t*1.0)\n",
    "    normalized_probs = get_denoise_probs(\n",
    "        denoise_logits=denoise_logits,\n",
    "        x_t=x_t*1.0,\n",
    "        batch=batch,\n",
    "        time=time,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "    print(normalized_probs[0])\n",
    "    loss+=cross_entropy(p=q_revs_loss, q=normalized_probs)\n",
    "    #x_1 = noiser.noise_x0_xt(\n",
    "    #    x0_batch=batch.x*1.0, \n",
    "    #    time_batch=torch.ones(size=(batch.batch_size,), dtype=torch.long)[batch.batch]\n",
    "    #)\n",
    "    #denoise_logits = torch.rand_like(x_t*1.0)\n",
    "    #q_forward = noiser.get_transition_probabilities(\n",
    "    #    x_t_batch=x_1*1.0,\n",
    "    #    time_batch=torch.ones(size=(batch.batch_size,), dtype=torch.long)[batch.batch],\n",
    "    #    scheduler=scheduler\n",
    "    #)\n",
    "    #print(noiser.accumulated_q_matrices[0])\n",
    "    #print(q_forward[0][0:2])\n",
    "    #normalized_probs = get_denoise_probs(\n",
    "    #    denoise_logits=denoise_logits,\n",
    "    #    x_t=x_1*1.0,\n",
    "    #    batch=batch,\n",
    "    #    time=torch.ones(size=(batch.batch_size,), dtype=torch.long),\n",
    "    #    scheduler=scheduler\n",
    "    #)\n",
    "    #print(x_1[8])\n",
    "    #print(normalized_probs)\n",
    "    #loss+=cross_entropy(p=q_forward, q=normalized_probs)\n",
    "    #print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fa2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(torch.tensor([0.0950, 0.2330, 0.1178, 0.1900, 0.1002, 0.1063, 0.1576]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8fcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cat_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
